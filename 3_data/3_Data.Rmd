---
title: "Data Practical 3"
author: "Stefano Politi"
date: "(`r format(Sys.time(), '%d %B %Y')`)"
output:
  github_document:
    toc: TRUE
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Required packages:

```{r packages}
library(dslabs)
library(readxl)
library(knitr)
```

## Importing R Pre-loaded Data

### Dataset 1

The [stars](https://www.rdocumentation.org/packages/dslabs/versions/0.7.4/topics/stars) dataset, from the dslabs package, describes the "Physical Properties of Stars".

```{r stars}
data(stars)
kable(head(stars, 10))
```

The structure of the dataset shows 96 observations of 4 variables.

The variables are listed here, with their respective data types and descriptions:

* star: factor variable (qualitative, categorical) indicating the name of the star.
* magnitude: numeric variable (quantitative, continuous) indicating the absolute magnitude of the star, as a function of its luminosity and distance.
* temp: integer -> numeric variable (quantitative, discrete) indicating the star's surface temperature in degrees Kelvin (K).
* type: character variable (qualitative, categorical) indicating the spectral class of the star in the OBAFGKM system.

```{r stars_structure}
str(stars)
```

## Importing External Data

### Dataset 2

The following dataset is taken from a study by Schaerlaeken, Glowinski and Grandjean (2021), aimed at investigating connections between metaphorical and emotional content in classical music.

The data can be found in free access at https://github.com/simonschaerlaeken/GEMMES.git

The dataset includes information on the participants, on the classical music excerpts used for the experiment, as well as participant ratings of the excerpts for the following scales:

* Geneva Emotion Musical Scale (GEMS): Evaluates perceived emotions while listening to music on a 9 factor model of "Joyful activation", "Nostalgia", "Peacefulness", "Power", "Sadness", "Tenderness", "Tension", "Transcendence" and "Wonder".
* Dimensional model of valence and arousal (VA): Evaluates perceived emotions while listening to music, on a 2 dimensional model of valence and arousal.
* Geneva Musical Metaphors Scale (GEMMES - VISU): Evaluates metaphorical content associated with listening to music on a 5 factor model of "Flow", "Force", "Interior", "Movement" and "Wondering".

```{r GEMMES}
library(readxl)
path  <- file.path("Exp2A-GEMMES_Binomial.xlsx")
GEMMES <- read_xlsx("Exp2A-GEMMES_Binomial.xlsx", sheet = 1)
kable(head(GEMMES, 10))
```

The structure of the dataset shows 7 200 observations of 100 variables.

The variables are listed here with their respective data types:

* Participant information:
  + Participant_ID: character variable (qualitative).
  + Sex: character variable (qualitative, categorical) indicating the sex of the participants (M for male, F for female).
  + Musician_type: numerical variable (quantitative, discrete) indicating the degree of musical expertise.
* Music excerpt information:
  + Excerpt_id: character variable (qualitative) indicating the composer and the title of a given excerpt.
  + Excerpt_GEMS: character variable (qualitative, categorical) indicating the GEMS emotion with which a given excerpt is associated to.
  + feat_***: numerical variables (quantitative, continuous) indicating acoustic and perceptual features of a given excerpt.
  + feat_***: character variables (qualitative, categorical) indicates acoustic and perceptual features of a given excerpt.
* Scales rating:
  + BEST_GEMS: character variable (qualitative, categorical) indicating the most rated emotion in the GEMS scale for a given excerpt.
  + GEMS_***: numerical variables(quantitative, discrete) indicating the individual rating of a given excerpt for each emotion in the GEMS scale.
  + BEST_VA: character variable (qualitative, categorical) indicating the most rated emotional dimension (valence or arousal) for a given excerpt.
  + VA***: numerical variable (quantitative, discrete) indicating the individual rating of a given excerpt for each emotional dimension.
  + BEST_VISU: character variable (qualitative, categorical) indicating the most rated metaphor in the GEMMES scale for a given excerpt.
  + VISU***: numerical variable (quantitative, discrete) indicating the individual rating of a given excerpt for each emotion in the GEMMES scale.

```{r GEMMES_structure}
str(GEMMES)
```

### Dataset 3

The following dataset is taken from a study by Lange, Fünderich and Grimm (2021), aimed at invesigating how visual and auditory information contribut to emotion communication during singing.

The data can be found in free access at https://osf.io/nf9g4/

The dataset contains all relevant participant information.



```{r participantData}
path  <- file.path("Participant_data_E12_age.sex.MSI.csv")
participantData <- read.csv(path)
kable(head(participantData, 10))
```

The structure of the dataset shows 66 observations for 35 variables.

The variables are listed here with their respective data types:

* SID: integer -> numerical variable (quantitative, discrete) indicating the subject ID.
* age: numerical variable (quantitative, discrete) indicating the age of the participants.
* sex: integer -> numerical variable (quantitative, discrete) indicating the sex of the participants (1 = female, 2 = male).
* prof: integer -> numerical variable (quantitative, discrete) indicating the profession of the participants (1 = student, 2 = not student).
* stud: integer -> numerical variable (quantitative, discrete) indicating the field of studies of the participants (1 = psychology, 2 = music, 3 = musicology, 4 = sound engineer, 5 = other music-related studies, 6 = other).
*MSI1-18: integer -> numerical variable (quantitative, discrete) indicating musical sophistication measured by the Gold MSI (Müllensiefen et al., 2014).
* OP1-10: integer -> numerical variable (quantitative, discrete) indicating responses on a 7-pt Likert Scale concerning questions regarding participants' experience with opera, song recital, etc.
* gold: integer -> numerical variable (quantitative, discrete) indicating the sum of MSI1-18.
* exp: integer -> numerical variable (quantitative, discrete) indicating evaluation of expertise (1 = laypersons, 2 = experts).

```{r participantData_structure}
str(participantData)
```

## References

Lange, E. B., Fünderich, J., & Grimm, H. (2022). Multisensory integration of musical emotion perception in singing. *Psychological Research*, *1-16*.

Schaerlaeken, S., Glowinski, D., & Grandjean, D. (2022). Linking musical metaphors and emotions evoked by the sound of classical music. *Psychology of music*, *50*(1), 245-264.