Data Practical 2
================
Stefano Politi
(20 juin 2022)

-   [Importing R Pre-loaded Data](#importing-r-pre-loaded-data)
    -   [Dataset 1](#dataset-1)
-   [Importing External Data](#importing-external-data)
    -   [Dataset 2](#dataset-2)
    -   [Dataset 3](#dataset-3)
-   [Bibliography](#bibliography)

## Importing R Pre-loaded Data

### Dataset 1

The stars dataset, from the dslabs package, describes the “Physical
Properties of Stars”

``` r
library(dslabs)
data(stars)
```

The structure of the dataset shows 96 observations of 4 variables.

The variables are listed here, with their respective data types and
descriptions (stars, Physical Properties of Stars in dslabs: Data
Science Labs, n. d.):

-   star: factor variable (qualitative, categorical) indicating the name
    of the star.
-   magnitude: numeric variable (quantitative, continuous) indicating
    the absolute magnitude of the star, as a function of its luminosity
    and distance.
-   temp: integer -\> numeric variable (quantitative, discrete)
    indicating the star’s surface temperature in degrees Kelvin (K).
-   type: character variable (qualitative, categorical) indicating the
    spectral class of the star in the OBAFGKM system.

``` r
str(stars)
```

    ## 'data.frame':    96 obs. of  4 variables:
    ##  $ star     : Factor w/ 95 levels "*40EridaniA",..: 87 85 48 38 33 92 49 79 77 47 ...
    ##  $ magnitude: num  4.8 1.4 -3.1 -0.4 4.3 0.5 -0.6 -7.2 2.6 -5.7 ...
    ##  $ temp     : int  5840 9620 7400 4590 5840 9900 5150 12140 6580 3200 ...
    ##  $ type     : chr  "G" "A" "F" "K" ...

## Importing External Data

### Dataset 2

The following dataset is taken from a study by Schaerlaeken, Glowinski
and Grandjean (2021), aimed at investigating connections between
metaphorical and emotional content in classical music.

The data can be found in free access at
<https://github.com/simonschaerlaeken/GEMMES.git>

The dataset includes information on the participants, on the classical
music excerpts used for the experiment, as well as participant ratings
of the excerpts for the following scales:

-   Geneva Emotion Musical Scale (GEMS): Evaluates perceived emotions
    while listening to music on a 9 factor model of “Joyful activation”,
    “Nostalgia”, “Peacefulness”, “Power”, “Sadness”, “Tenderness”,
    “Tension”, “Transcendence” and “Wonder”.
-   Dimensional model of valence and arousal (VA): Evaluates perceived
    emotions while listening to music, on a 2 dimensional model of
    valence and arousal.
-   Geneva Musical Metaphors Scale (GEMMES - VISU): Evaluates
    metaphorical content associated with listening to music on a 5
    factor model of “Flow”, “Force”, “Interior”, “Movement” and
    “Wondering”.

``` r
library(readxl)
path  <- file.path("/home/itopie/Documents/Data Science/IntroDataScience/Data", "Exp2A-GEMMES_Binomial.xlsx")
GEMMES <- read_xlsx(path, sheet = 1)
```

The structure of the dataset shows 7 200 observations of 100 variables.

The variables are listed here with their respective data types:

-   Participant information:
    -   Participant_ID: character variable (qualitative).
    -   Sex: character variable (qualitative, categorical) indicating
        the sex of the participants (M for male, F for female).
    -   Musician_type: numerical variable (quantitative, discrete)
        indicating the degree of musical expertise.
-   Music excerpt information:
    -   Excerpt_id: character variable (qualitative) indicating the
        composer and the title of a given excerpt.
    -   Excerpt_GEMS: character variable (qualitative, categorical)
        indicating the GEMS emotion with which a given excerpt is
        associated to.
    -   feat\_\*\*\*: numerical variables (quantitative, continuous)
        indicating acoustic and perceptual features of a given excerpt.
    -   feat\_\*\*\*: character variables (qualitative, categorical)
        indicates acoustic and perceptual features of a given excerpt.
-   Scales rating:
    -   BEST_GEMS: character variable (qualitative, categorical)
        indicating the most rated emotion in the GEMS scale for a given
        excerpt.
    -   GEMS\_\*\*\*: numerical variables(quantitative, discrete)
        indicating the individual rating of a given excerpt for each
        emotion in the GEMS scale.
    -   BEST_VA: character variable (qualitative, categorical)
        indicating the most rated emotional dimension (valence or
        arousal) for a given excerpt.
    -   VA\*\*\*: numerical variable (quantitative, discrete) indicating
        the individual rating of a given excerpt for each emotional
        dimension.
    -   BEST_VISU: character variable (qualitative, categorical)
        indicating the most rated metaphor in the GEMMES scale for a
        given excerpt.
    -   VISU\*\*\*: numerical variable (quantitative, discrete)
        indicating the individual rating of a given excerpt for each
        emotion in the GEMMES scale.

``` r
str(GEMMES)
```

    ## tibble [7,200 × 100] (S3: tbl_df/tbl/data.frame)
    ##  $ Participant_ID                  : chr [1:7200] "R_10q7ugZebPq8d4x" "R_10q7ugZebPq8d4x" "R_10q7ugZebPq8d4x" "R_10q7ugZebPq8d4x" ...
    ##  $ Sex                             : chr [1:7200] "M" "M" "M" "M" ...
    ##  $ Age                             : num [1:7200] 28 28 28 28 28 28 28 28 28 28 ...
    ##  $ Musician_type                   : num [1:7200] 3 3 3 3 3 3 3 3 3 3 ...
    ##  $ Excerpt_id                      : chr [1:7200] "bach_brandenburgconcerto" "bach_brandenburgconcerto" "bach_brandenburgconcerto" "bach_brandenburgconcerto" ...
    ##  $ Excerpt_GEMS                    : chr [1:7200] "Sadness" "Sadness" "Sadness" "Sadness" ...
    ##  $ feat_ENT_Agitated               : num [1:7200] 1.5 1.5 1.5 1.5 1.5 ...
    ##  $ feat_ENT_Animated               : num [1:7200] 2.23 2.23 2.23 2.23 2.23 ...
    ##  $ feat_ENT_Beat                   : num [1:7200] 1.34 1.34 1.34 1.34 1.34 ...
    ##  $ feat_ENT_Dance                  : num [1:7200] 1.06 1.06 1.06 1.06 1.06 ...
    ##  $ feat_ENT_Entrained              : num [1:7200] 1.15 1.15 1.15 1.15 1.15 ...
    ##  $ feat_ENT_Move                   : num [1:7200] 1.12 1.12 1.12 1.12 1.12 ...
    ##  $ feat_ENT_PCvic                  : num [1:7200] 1.66 1.66 1.66 1.66 1.66 ...
    ##  $ feat_ENT_Pcmot                  : num [1:7200] 0.883 0.883 0.883 0.883 0.883 ...
    ##  $ feat_ENT_Physio                 : num [1:7200] 2.16 2.16 2.16 2.16 2.16 ...
    ##  $ feat_ENT_Resonate               : num [1:7200] 2.9 2.9 2.9 2.9 2.9 3.05 3.05 3.05 3.05 3.05 ...
    ##  $ feat_ENT_Rhythm                 : num [1:7200] 2.31 2.31 2.31 2.31 2.31 ...
    ##  $ feat_KNOW                       : num [1:7200] 1.72 1.72 1.72 1.72 1.72 ...
    ##  $ feat_PC1                        : num [1:7200] -0.367 -0.367 -0.367 -0.367 -0.367 ...
    ##  $ feat_PC2                        : num [1:7200] -1.17 -1.17 -1.17 -1.17 -1.17 ...
    ##  $ feat_PC3                        : num [1:7200] -1.72 -1.72 -1.72 -1.72 -1.72 ...
    ##  $ feat_PC4                        : num [1:7200] 1.02 1.02 1.02 1.02 1.02 ...
    ##  $ feat_PC_ENT                     : num [1:7200] -1.25 -1.25 -1.25 -1.25 -1.25 ...
    ##  $ feat_articulation               : num [1:7200] 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 2.4 ...
    ##  $ feat_atonality                  : num [1:7200] 7.6 7.6 7.6 7.6 7.6 7.2 7.2 7.2 7.2 7.2 ...
    ##  $ feat_dissonance                 : num [1:7200] 3.6 3.6 3.6 3.6 3.6 2.8 2.8 2.8 2.8 2.8 ...
    ##  $ feat_melody                     : num [1:7200] 8.2 8.2 8.2 8.2 8.2 7.8 7.8 7.8 7.8 7.8 ...
    ##  $ feat_mode                       : num [1:7200] 6.2 6.2 6.2 6.2 6.2 3.8 3.8 3.8 3.8 3.8 ...
    ##  $ feat_rhythm_complexity          : num [1:7200] 4.8 4.8 4.8 4.8 4.8 4.2 4.2 4.2 4.2 4.2 ...
    ##  $ feat_rhythm_stability           : num [1:7200] 5.4 5.4 5.4 5.4 5.4 4.2 4.2 4.2 4.2 4.2 ...
    ##  $ feat_norm_ENT_Agitated          : num [1:7200] 0.146 0.146 0.146 0.146 0.146 ...
    ##  $ feat_norm_ENT_Animated          : num [1:7200] 0.227 0.227 0.227 0.227 0.227 ...
    ##  $ feat_norm_ENT_Beat              : num [1:7200] 0.176 0.176 0.176 0.176 0.176 ...
    ##  $ feat_norm_ENT_Dance             : num [1:7200] 0.206 0.206 0.206 0.206 0.206 ...
    ##  $ feat_norm_ENT_Entrained         : num [1:7200] 0.157 0.157 0.157 0.157 0.157 ...
    ##  $ feat_norm_ENT_Move              : num [1:7200] 0.135 0.135 0.135 0.135 0.135 ...
    ##  $ feat_norm_ENT_PCvic             : num [1:7200] 0.176 0.176 0.176 0.176 0.176 ...
    ##  $ feat_norm_ENT_Pcmot             : num [1:7200] 0.177 0.177 0.177 0.177 0.177 ...
    ##  $ feat_norm_ENT_Physio            : num [1:7200] 0.152 0.152 0.152 0.152 0.152 ...
    ##  $ feat_norm_ENT_Resonate          : num [1:7200] 0.267 0.267 0.267 0.267 0.267 ...
    ##  $ feat_norm_ENT_Rhythm            : num [1:7200] 0.244 0.244 0.244 0.244 0.244 ...
    ##  $ feat_norm_KNOW                  : num [1:7200] 0.171 0.171 0.171 0.171 0.171 ...
    ##  $ feat_norm_PC1                   : num [1:7200] 0.571 0.571 0.571 0.571 0.571 ...
    ##  $ feat_norm_PC2                   : num [1:7200] 0.409 0.409 0.409 0.409 0.409 ...
    ##  $ feat_norm_PC3                   : num [1:7200] 0.169 0.169 0.169 0.169 0.169 ...
    ##  $ feat_norm_PC4                   : num [1:7200] 0.613 0.613 0.613 0.613 0.613 ...
    ##  $ feat_norm_PC_ENT                : num [1:7200] 0.182 0.182 0.182 0.182 0.182 ...
    ##  $ feat_norm_articulation          : num [1:7200] 0.167 0.167 0.167 0.167 0.167 ...
    ##  $ feat_norm_atonality             : num [1:7200] 0.7 0.7 0.7 0.7 0.7 0.6 0.6 0.6 0.6 0.6 ...
    ##  $ feat_norm_dissonance            : num [1:7200] 0.259 0.259 0.259 0.259 0.259 ...
    ##  $ feat_norm_melody                : num [1:7200] 0.833 0.833 0.833 0.833 0.833 ...
    ##  $ feat_norm_mode                  : num [1:7200] 0.64 0.64 0.64 0.64 0.64 0.16 0.16 0.16 0.16 0.16 ...
    ##  $ feat_norm_rhythm_complexity     : num [1:7200] 0.529 0.529 0.529 0.529 0.529 ...
    ##  $ feat_norm_rhythm_stability      : num [1:7200] 0.367 0.367 0.367 0.367 0.367 ...
    ##  $ feat_norm_fact_ENT_Agitated     : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Animated     : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Beat         : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Dance        : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Entrained    : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Move         : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_PCvic        : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Pcmot        : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Physio       : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Resonate     : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_ENT_Rhythm       : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_KNOW             : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_PC1              : chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ feat_norm_fact_PC2              : chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ feat_norm_fact_PC3              : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_PC4              : chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ feat_norm_fact_PC_ENT           : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_articulation     : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_atonality        : chr [1:7200] "c100" "c100" "c100" "c100" ...
    ##  $ feat_norm_fact_dissonance       : chr [1:7200] "a33" "a33" "a33" "a33" ...
    ##  $ feat_norm_fact_melody           : chr [1:7200] "c100" "c100" "c100" "c100" ...
    ##  $ feat_norm_fact_mode             : chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ feat_norm_fact_rhythm_complexity: chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ feat_norm_fact_rhythm_stability : chr [1:7200] "b66" "b66" "b66" "b66" ...
    ##  $ BEST_GEMS                       : chr [1:7200] "GEMS_Nostalgia" "GEMS_Nostalgia" "GEMS_Nostalgia" "GEMS_Nostalgia" ...
    ##  $ GEMS_JoyfulActivation           : num [1:7200] 8 8 8 8 8 29 29 29 29 29 ...
    ##  $ GEMS_Nostalgia                  : num [1:7200] 48 48 48 48 48 52 52 52 52 52 ...
    ##  $ GEMS_Peacefulness               : num [1:7200] 28 28 28 28 28 61 61 61 61 61 ...
    ##  $ GEMS_Power                      : num [1:7200] 14 14 14 14 14 3 3 3 3 3 ...
    ##  $ GEMS_Sadness                    : num [1:7200] 47 47 47 47 47 25 25 25 25 25 ...
    ##  $ GEMS_Tenderness                 : num [1:7200] 35 35 35 35 35 63 63 63 63 63 ...
    ##  $ GEMS_Tension                    : num [1:7200] 7 7 7 7 7 0 0 0 0 0 ...
    ##  $ GEMS_Transcendence              : num [1:7200] 25 25 25 25 25 20 20 20 20 20 ...
    ##  $ GEMS_Wonder                     : num [1:7200] 26 26 26 26 26 41 41 41 41 41 ...
    ##  $ BEST_VA                         : chr [1:7200] "VA_Arousal" "VA_Arousal" "VA_Arousal" "VA_Arousal" ...
    ##  $ VA_Arousal                      : num [1:7200] 48 48 48 48 48 47 47 47 47 47 ...
    ##  $ VA_Valence                      : num [1:7200] 34 34 34 34 34 69 69 69 69 69 ...
    ##  $ BEST_VISU                       : chr [1:7200] "VISU_Flow" "VISU_Flow" "VISU_Flow" "VISU_Flow" ...
    ##  $ VISU_Flow                       : num [1:7200] 55 55 55 55 55 63 63 63 63 63 ...
    ##  $ VISU_Force                      : num [1:7200] 22 22 22 22 22 12 12 12 12 12 ...
    ##  $ VISU_Interior                   : num [1:7200] 49 49 49 49 49 43 43 43 43 43 ...
    ##  $ VISU_Movement                   : num [1:7200] 24 24 24 24 24 26 26 26 26 26 ...
    ##  $ VISU_Wandering                  : num [1:7200] 27 27 27 27 27 29 29 29 29 29 ...
    ##  $ VISU                            : chr [1:7200] "VISU_Flow" "VISU_Force" "VISU_Interior" "VISU_Movement" ...
    ##  $ VISU_Value                      : num [1:7200] 7 2 4 4 1 4 6 7 2 0 ...
    ##   [list output truncated]

### Dataset 3

The following dataset is taken from a study by Lange, Fünderich and
Grimm (2021), aimed at invesigating how visual and auditory information
contribut to emotion communication during singing.

The data can be found in free access at <https://osf.io/nf9g4/>

The dataset contains all relevant participant information.

``` r
path  <- file.path("/home/itopie/Documents/Data Science/IntroDataScience/Data", "Participant_data_E12_age.sex.MSI.csv")
participantData <- read.csv(path)
```

The structure of the dataset shows 66 observations for 35 variables.

The variables are listed here with their respective data types:

-   SID: integer -\> numerical variable (quantitative, discrete)
    indicating the subject ID.
-   age: numerical variable (quantitative, discrete) indicating the age
    of the participants.
-   sex: integer -\> numerical variable (quantitative, discrete)
    indicating the sex of the participants (1 = female, 2 = male).
-   prof: integer -\> numerical variable (quantitative, discrete)
    indicating the profession of the participants (1 = student, 2 = not
    student).
-   stud: integer -\> numerical variable (quantitative, discrete)
    indicating the field of studies of the participants (1 = psychology,
    2 = music, 3 = musicology, 4 = sound engineer, 5 = other
    music-related studies, 6 = other). \*MSI1-18: integer -\> numerical
    variable (quantitative, discrete) indicating musical sophistication
    measured by the Gold MSI (Müllensiefen et al., 2014).
-   OP1-10: integer -\> numerical variable (quantitative, discrete)
    indicating responses on a 7-pt Likert Scale concerning questions
    regarding participants’ experience with opera, song recital, etc.
-   gold: integer -\> numerical variable (quantitative, discrete)
    indicating the sum of MSI1-18.
-   exp: integer -\> numerical variable (quantitative, discrete)
    indicating evaluation of expertise (1 = laypersons, 2 = experts).

``` r
str(participantData)
```

    ## 'data.frame':    66 obs. of  35 variables:
    ##  $ SID  : int  1 2 3 4 5 6 7 8 9 10 ...
    ##  $ age  : num  24 21 32 21 22 20 23 29 29 19 ...
    ##  $ sex  : int  1 2 1 2 1 1 1 1 2 1 ...
    ##  $ prof : int  1 1 1 1 1 1 1 1 1 1 ...
    ##  $ stud : int  6 6 6 6 6 6 6 6 6 6 ...
    ##  $ MSI1 : int  6 1 1 6 3 7 4 4 5 7 ...
    ##  $ MSI2 : int  2 1 5 2 1 4 1 1 2 1 ...
    ##  $ MSI3 : int  5 2 7 5 2 1 4 3 2 2 ...
    ##  $ MSI4 : int  6 6 4 7 5 5 5 4 6 7 ...
    ##  $ MSI5 : int  5 3 7 6 2 1 3 3 6 5 ...
    ##  $ MSI6 : int  6 6 7 6 3 3 2 4 6 6 ...
    ##  $ MSI7 : int  6 3 7 7 4 5 2 6 6 7 ...
    ##  $ MSI8 : int  6 7 7 6 2 7 2 3 5 7 ...
    ##  $ MSI9 : int  6 2 7 3 1 2 5 2 6 5 ...
    ##  $ MSI10: int  6 5 7 6 3 3 3 5 6 5 ...
    ##  $ MSI11: int  5 2 7 6 5 5 5 2 6 6 ...
    ##  $ MSI12: int  6 7 7 5 2 3 5 5 2 6 ...
    ##  $ MSI13: int  5 1 7 5 1 2 3 7 3 5 ...
    ##  $ MSI14: int  2 2 6 4 2 3 1 5 2 2 ...
    ##  $ MSI15: int  5 4 6 5 1 7 4 3 6 6 ...
    ##  $ MSI16: int  4 7 6 4 4 5 7 5 7 5 ...
    ##  $ MSI17: int  3 7 6 1 1 1 7 3 7 3 ...
    ##  $ MSI18: int  1 7 1 1 2 3 7 3 1 2 ...
    ##  $ OP1  : int  4 4 7 4 1 5 3 5 4 2 ...
    ##  $ OP2  : int  3 3 3 6 1 1 5 4 5 1 ...
    ##  $ OP3  : int  6 5 7 6 2 5 6 7 6 1 ...
    ##  $ OP4  : int  7 4 1 2 6 7 2 2 6 4 ...
    ##  $ OP5  : int  3 1 2 2 1 2 2 1 2 4 ...
    ##  $ OP6  : int  4 1 1 1 1 1 1 1 2 3 ...
    ##  $ OP7  : int  6 1 1 1 2 3 1 4 2 3 ...
    ##  $ OP8  : int  5 2 1 2 1 1 1 4 3 1 ...
    ##  $ OP9  : int  2 2 2 5 6 5 5 2 6 5 ...
    ##  $ OP10 : int  4 1 6 2 3 3 2 1 6 1 ...
    ##  $ gold : int  85 73 105 85 44 67 70 68 84 87 ...
    ##  $ exp  : int  1 1 1 1 1 1 1 1 1 1 ...

## Bibliography

Lange, E. B., Fünderich, J., & Grimm, H. (2022). Multisensory
integration of musical emotion perception in singing. Psychological
Research, 1-16.

Schaerlaeken, S., Glowinski, D., & Grandjean, D. (2022). Linking musical
metaphors and emotions evoked by the sound of classical music.
*Psychology of music*, 50(1), 245-264.

*stars: Physical Properties of Stars in dslabs: Data Science Labs*
(n.d.). Rdrr.io. Retrieved June 19, 2022, from
<https://rdrr.io/cran/dslabs/man/stars.html>
